# Environment Configuration for Logistics Multi-Agent System
# ========================================================

# LLM Backend Configuration
# Options: "ollama" (local development) or "bedrock" (AWS production)
LLM_BACKEND=ollama

# Ollama Configuration (Local Development)
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=llama3:latest

# AWS Bedrock Configuration (Production)
AWS_REGION=us-east-1
BEDROCK_MODEL=anthropic.claude-3-sonnet-20240229-v1:0

# Strands Framework Configuration
ENABLE_STRANDS_OBSERVABILITY=true
ENABLE_STRANDS_METRICS=true
ENABLE_AGENT_STREAMING=true

# Flask Configuration
FLASK_HOST=0.0.0.0
FLASK_PORT=5555
FLASK_DEBUG=false

# Logging Configuration
LOG_LEVEL=INFO